{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder, PolynomialFeatures, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, RidgeClassifier, Ridge, Lasso, LinearRegression, SGDRegressor, HuberRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIGHTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATAFRAMES\n",
    "df_flights = pd.read_csv('flights_250k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE AIRPORTS AND TAILNUM\n",
    "encoder = OrdinalEncoder()\n",
    "df_flights['mkt_carrier'] = encoder.fit_transform(df_flights[['mkt_carrier']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAB RELEVANT COLUMNS\n",
    "X = df_flights[[\n",
    "    'fl_date',\n",
    "    'mkt_carrier',\n",
    "    'origin_airport_id',\n",
    "    'dest_airport_id',\n",
    "    'crs_dep_time',\n",
    "    'crs_arr_time',\n",
    "    'crs_elapsed_time',\n",
    "    'distance',\n",
    "    \n",
    "    'dep_delay',\n",
    "    'nas_delay',\n",
    "    'carrier_delay'\n",
    "]].copy()\n",
    "\n",
    "y = df_flights['arr_delay'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING\n",
    "\n",
    "# TURNS DATE INTO MONTHS\n",
    "X['fl_date'] = X['fl_date'].str[5:7]\n",
    "X['fl_date'] = X['fl_date'].astype(int)\n",
    "\n",
    "# TURNS TIME INTO HOURS\n",
    "X['crs_dep_time'] = X['crs_dep_time'] // 100\n",
    "X['crs_arr_time'] = X['crs_arr_time'] // 100\n",
    "X['crs_dep_time'].replace(24.0, 0.0, inplace=True)\n",
    "X['crs_arr_time'].replace(24.0, 0.0, inplace=True)\n",
    "\n",
    "X.fillna(0, inplace=True)\n",
    "y.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.2)\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "y_train = y_train.copy()\n",
    "y_test = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTORICAL DATA\n",
    "\n",
    "# ORIGIN AIRPORT NAS DELAY\n",
    "origin_airport_data = X_train.groupby(by=['fl_date', 'origin_airport_id'])['nas_delay'].mean().to_dict()\n",
    "\n",
    "def get_origin_delay(x):\n",
    "    if (x['fl_date'], x['origin_airport_id']) in origin_airport_data:\n",
    "        return origin_airport_data[(x['fl_date'], x['origin_airport_id'])]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "X_train['origin_delay'] = X_train.apply(get_origin_delay, axis=1)\n",
    "\n",
    "# DEST AIRPORT NAS DELAY\n",
    "dest_airport_data = X_train.groupby(by=['fl_date', 'dest_airport_id'])['nas_delay'].mean().to_dict()\n",
    "\n",
    "def get_dest_delay(x):\n",
    "    if (x['fl_date'], x['dest_airport_id']) in dest_airport_data:\n",
    "        return dest_airport_data[(x['fl_date'], x['dest_airport_id'])]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "X_train['dest_delay'] = X_train.apply(get_dest_delay, axis=1)\n",
    "\n",
    "# CARRIER DELAY\n",
    "carrier_data = X_train.groupby(by=['fl_date', 'mkt_carrier'])['carrier_delay'].mean().to_dict()\n",
    "\n",
    "def get_carrier_delay(x):\n",
    "    if (x['fl_date'], x['mkt_carrier']) in carrier_data:\n",
    "        return carrier_data[(x['fl_date'], x['mkt_carrier'])]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "X_train['carr_delay'] = X_train.apply(get_carrier_delay, axis=1)\n",
    "\n",
    "# BIN HISTORICAL DATA\n",
    "origin_minmax = MinMaxScaler(feature_range=(1,5))\n",
    "dest_minmax = MinMaxScaler(feature_range=(1,5))\n",
    "carrier_minmax = MinMaxScaler(feature_range=(1,5))\n",
    "\n",
    "X_train['origin_delay'] = origin_minmax.fit_transform(X_train[['origin_delay']])\n",
    "X_train['dest_delay'] = dest_minmax.fit_transform(X_train[['dest_delay']])\n",
    "X_train['carr_delay'] = carrier_minmax.fit_transform(X_train[['carr_delay']])\n",
    "\n",
    "X_train['origin_delay'] = X_train['origin_delay'].round(0)\n",
    "X_train['dest_delay'] = X_train['dest_delay'].round(0)\n",
    "X_train['carr_delay'] = X_train['carr_delay'].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY HISTORICAL DATA TO TEST\n",
    "X_test['origin_delay'] = X_test.apply(get_origin_delay, axis=1)\n",
    "X_test['dest_delay'] = X_test.apply(get_dest_delay, axis=1)\n",
    "X_test['carr_delay'] = X_test.apply(get_carrier_delay, axis=1)\n",
    "\n",
    "#BIN HISTORICAL DATA\n",
    "X_test['origin_delay'] = origin_minmax.transform(X_test[['origin_delay']])\n",
    "X_test['dest_delay'] = dest_minmax.transform(X_test[['dest_delay']])\n",
    "X_test['carr_delay'] = carrier_minmax.transform(X_test[['carr_delay']])\n",
    "\n",
    "X_test['origin_delay'] = X_test['origin_delay'].round(0)\n",
    "X_test['dest_delay'] = X_test['dest_delay'].round(0)\n",
    "X_test['carr_delay'] = X_test['carr_delay'].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP HISTORICAL DATA\n",
    "X_train.drop(columns=['carrier_delay', 'nas_delay', 'dep_delay', 'origin_airport_id', 'dest_airport_id', 'mkt_carrier'], inplace=True)\n",
    "X_test.drop(columns=['carrier_delay', 'nas_delay', 'dep_delay', 'origin_airport_id', 'dest_airport_id', 'mkt_carrier'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # MODEL CLASSIFICATION\n",
    "# scaler = StandardScaler()\n",
    "# poly = PolynomialFeatures(2)\n",
    "\n",
    "# # create function for apply\n",
    "# def relabel_y(x):\n",
    "#     if x > 0:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# #random forest for classification\n",
    "# ran_forest = RandomForestClassifier(\n",
    "#     n_estimators=300,\n",
    "#     n_jobs=2\n",
    "# )\n",
    "\n",
    "# #ridge classifier\n",
    "# # ran_forest = RidgeClassifier()\n",
    "\n",
    "# # relabel y for classification\n",
    "# y_train_class = y_train.apply(relabel_y)\n",
    "# y_test_class = y_test.apply(relabel_y)\n",
    "\n",
    "# # apply fit, predict\n",
    "# ran_forest.fit(\n",
    "#     scaler.fit_transform(poly.fit_transform(X_train)),\n",
    "#     y_train_class\n",
    "# )\n",
    "# y_train_class_pred = ran_forest.predict(\n",
    "#     scaler.fit_transform(poly.fit_transform(X_train))\n",
    "# )\n",
    "# y_test_class_pred =  ran_forest.predict(\n",
    "#     scaler.fit_transform(poly.fit_transform(X_test))\n",
    "# )\n",
    "\n",
    "# # add delay feature to X\n",
    "# X_train['delay'] = y_train_class_pred\n",
    "# X_test['delay'] = y_test_class_pred\n",
    "\n",
    "# #show prediction accuracy based on available data\n",
    "# accuracy_score(y_test_class, y_test_class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# MODEL REGRESSION SELECTION :)\n",
    "# model = RandomForestRegressor(\n",
    "#     n_estimators=200,\n",
    "#     n_jobs=2\n",
    "# )\n",
    "\n",
    "# model = ElasticNet(\n",
    "#      alpha=1,\n",
    "#      l1_ratio=0.5\n",
    "# )\n",
    "\n",
    "# model = SGDRegressor()\n",
    "\n",
    "# model = HuberRegressor()\n",
    "\n",
    "# model = GradientBoostingRegressor()\n",
    "\n",
    "# model = AdaBoostRegressor()\n",
    "\n",
    "# model = xgb.XGBRegressor()\n",
    "\n",
    "# BEST SO FAR\n",
    "# model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL REGRESSION\n",
    "model = LinearRegression()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=4)\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "# WITH PCA\n",
    "# model.fit(\n",
    "#     pca.fit_transform(scaler.fit_transform(poly.fit_transform(X_train))), y_train\n",
    "# )\n",
    "\n",
    "#WITH SCALING\n",
    "# model.fit(\n",
    "#     scaler.fit_transform(X_train), y_train\n",
    "# )\n",
    "\n",
    "# WITH POLY AND SCALING\n",
    "model.fit(\n",
    "    scaler.fit_transform(poly.fit_transform(X_train)), y_train\n",
    ")\n",
    "\n",
    "# WITH POLY\n",
    "# model.fit(\n",
    "#     poly.fit_transform(X_train), y_train\n",
    "# )\n",
    "\n",
    "# NO SCALING\n",
    "# model.fit(\n",
    "#     X_train, y_train\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.9533851539187\n",
      "0.013070254232745993\n"
     ]
    }
   ],
   "source": [
    "# MODEL PREDICTION AND SCORE\n",
    "\n",
    "# WITH PCA\n",
    "# y_pred = model.predict(\n",
    "#     pca.transform(scaler.transform(poly.fit_transform(X_test)))\n",
    "# )\n",
    "\n",
    "#WITH SCALING\n",
    "# y_pred = model.predict(\n",
    "#     scaler.transform(X_test)\n",
    "# )\n",
    "\n",
    "# WITH POLY AND SCALING\n",
    "y_pred = model.predict(\n",
    "    scaler.fit_transform(poly.fit_transform(X_test))\n",
    ")\n",
    "\n",
    "# WITH POLY\n",
    "# y_pred = model.predict(\n",
    "#     poly.fit_transform(X_test)\n",
    "# )\n",
    "\n",
    "# NO SCALING\n",
    "# y_pred = model.predict(\n",
    "#     X_test\n",
    "# )\n",
    "\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL PERSISTENCE\n",
    "import pickle\n",
    "filename = 'linear_1.5.sav'\n",
    "\n",
    "# SAVE MODEL\n",
    "# pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# LOAD MODEL\n",
    "# model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIGHTS TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATAFRAMES\n",
    "df_test = pd.read_csv('flights_test_first_week.csv')\n",
    "\n",
    "# ENCODE AIRPORTS AND TAILNUM\n",
    "df_test['mkt_carrier'] = encoder.transform(df_test[['mkt_carrier']])\n",
    "\n",
    "# GRAB RELEVANT COLUMNS\n",
    "X_ = df_test[[\n",
    "    'fl_date',\n",
    "    'mkt_carrier',\n",
    "    'origin_airport_id',\n",
    "    'dest_airport_id',\n",
    "    'crs_dep_time',\n",
    "    'crs_arr_time',\n",
    "    'crs_elapsed_time',\n",
    "    'distance'\n",
    "]].copy()\n",
    "\n",
    "# FEATURE ENGINEERING\n",
    "X_['fl_date'] = X_['fl_date'].str[5:7]\n",
    "X_['fl_date'] = X_['fl_date'].astype(int)\n",
    "\n",
    "X_['crs_dep_time'] = X_['crs_dep_time'] // 100\n",
    "X_['crs_arr_time'] = X_['crs_arr_time'] // 100\n",
    "X_['crs_dep_time'].replace(24.0, 0.0, inplace=True)\n",
    "X_['crs_arr_time'].replace(24.0, 0.0, inplace=True)\n",
    "\n",
    "X_.fillna(0, inplace=True)\n",
    "\n",
    "# APPLY HISTORICAL DATA TO TEST\n",
    "X_['origin_delay'] = X_.apply(get_origin_delay, axis=1)\n",
    "X_['dest_delay'] = X_.apply(get_dest_delay, axis=1)\n",
    "X_['carr_delay'] = X_.apply(get_carrier_delay, axis=1)\n",
    "\n",
    "X_['origin_delay'] = origin_minmax.transform(X_[['origin_delay']])\n",
    "X_['dest_delay'] = dest_minmax.transform(X_[['dest_delay']])\n",
    "X_['carr_delay'] = carrier_minmax.transform(X_[['carr_delay']])\n",
    "\n",
    "X_['origin_delay'] = X_['origin_delay'].round(0)\n",
    "X_['dest_delay'] = X_['dest_delay'].round(0)\n",
    "X_['carr_delay'] = X_['carr_delay'].round(0)\n",
    "\n",
    "X_.drop(columns=['origin_airport_id', 'dest_airport_id', 'mkt_carrier'], inplace=True)\n",
    "\n",
    "# WITH POLY\n",
    "y_pred_ = model.predict(\n",
    "    scaler.fit_transform(poly.fit_transform(X_))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAB RELEVANT COLUMNS\n",
    "X_final = df_test[[\n",
    "    'fl_date',\n",
    "    'mkt_carrier',\n",
    "    'mkt_carrier_fl_num',\n",
    "    'origin',\n",
    "    'dest'\n",
    "]].copy()\n",
    "\n",
    "X_final['predicted_delay'] = y_pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final.to_csv('prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
